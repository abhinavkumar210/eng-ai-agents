{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90e616d7",
   "metadata": {},
   "source": [
    "# Assignment 1 Coding\n",
    "\n",
    "Abhinav Kumar\n",
    "9/21/2025\n",
    "\n",
    "Custom Torchvision dataset: 25 points\n",
    "Transformations: 25 points\n",
    "Visualization: 25 points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "febdd7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WS         : /workspaces/eng-ai-agents/assignments/assignment-1\n",
      "DATA_DIR   : /workspaces/eng-ai-agents/assignments/assignment-1/data\n",
      "VIDEO_PATH : /workspaces/eng-ai-agents/assignments/assignment-1/data/video.mp4 exists: True\n",
      "ASTRONAUT  : /workspaces/eng-ai-agents/assignments/assignment-1/data/astronaut.jpg exists: True\n",
      "torch: 2.8.0+cpu\n",
      "torchvision: 0.23.0+cpu\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os, torch, torchvision, av\n",
    "import torchvision.io as io\n",
    "import torchvision.transforms.v2 as v2\n",
    "from torchvision.utils import make_grid, save_image\n",
    "\n",
    "ROOT   = Path(\"/workspaces/eng-ai-agents\").resolve()\n",
    "WS     = (ROOT / \"assignments/assignment-1\").resolve()\n",
    "\n",
    "DATA_DIR    = (WS / \"data\").resolve()\n",
    "FRAMES_DIR  = (DATA_DIR / \"frames\").resolve()\n",
    "PREVIEW_DIR = (DATA_DIR / \"preview\").resolve()\n",
    "\n",
    "VIDEO_PATH = DATA_DIR / \"video.mp4\"\n",
    "ASTRONAUT_PATH = DATA_DIR / \"astronaut.jpg\"\n",
    "\n",
    "for d in (DATA_DIR, FRAMES_DIR, PREVIEW_DIR):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"WS         :\", WS)\n",
    "print(\"DATA_DIR   :\", DATA_DIR)\n",
    "print(\"VIDEO_PATH :\", VIDEO_PATH, \"exists:\", VIDEO_PATH.exists())\n",
    "print(\"ASTRONAUT  :\", ASTRONAUT_PATH, \"exists:\", ASTRONAUT_PATH.exists())\n",
    "\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"torchvision:\", torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78d9999d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1000 frames → /workspaces/eng-ai-agents/assignments/assignment-1/data/frames (backend: PyAV)\n"
     ]
    }
   ],
   "source": [
    "MAX_FRAMES = 1000\n",
    "\n",
    "with av.open(str(VIDEO_PATH)) as container:\n",
    "    total = 0\n",
    "    for _ in container.decode(video=0):\n",
    "        total += 1\n",
    "\n",
    "if total == 0:\n",
    "    raise RuntimeError(\"No frames decoded from the video. Check VIDEO_PATH or install ffmpeg/PyAV correctly.\")\n",
    "\n",
    "target = min(MAX_FRAMES, total)\n",
    "idxs = torch.linspace(0, total - 1, steps=target).round().to(torch.int64)\n",
    "keep = set(int(i) for i in idxs.tolist())\n",
    "\n",
    "saved = 0\n",
    "with av.open(str(VIDEO_PATH)) as container:\n",
    "    for i, frame in enumerate(container.decode(video=0)):\n",
    "        if i in keep:\n",
    "            arr = frame.to_ndarray(format=\"rgb24\")\n",
    "            img = torch.from_numpy(arr).permute(2, 0, 1)\n",
    "            save_image(img.float() / 255.0, str(FRAMES_DIR / f\"frame_{saved:05d}.png\"))\n",
    "            saved += 1\n",
    "            if saved >= target:\n",
    "                break\n",
    "\n",
    "print(f\"Saved {saved} frames → {FRAMES_DIR} (backend: PyAV)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ddd4675a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: [0.386422723531723, 0.35811859369277954, 0.3309529721736908]\n",
      "std : [0.2662123143672943, 0.1989150494337082, 0.17553561925888062]\n"
     ]
    }
   ],
   "source": [
    "files = sorted([os.path.join(FRAMES_DIR, f) for f in os.listdir(FRAMES_DIR)\n",
    "                if f.lower().endswith((\".png\",\".jpg\",\".jpeg\",\".bmp\",\".webp\"))])\n",
    "\n",
    "sum_c   = torch.zeros(3, dtype=torch.float64)\n",
    "sumsq_c = torch.zeros(3, dtype=torch.float64)\n",
    "total_px = 0\n",
    "\n",
    "for p in files:\n",
    "    x = io.read_image(p).to(torch.float32) / 255.0  # C,H,W in [0,1]\n",
    "    c, h, w = x.shape\n",
    "    flat = x.reshape(c, -1)\n",
    "    sum_c   += flat.sum(dim=1, dtype=torch.float64)\n",
    "    sumsq_c += (flat**2).sum(dim=1, dtype=torch.float64)\n",
    "    total_px += h * w\n",
    "\n",
    "mean = (sum_c / total_px).to(torch.float32)\n",
    "var  = (sumsq_c / total_px - (mean.to(torch.float64)**2)).to(torch.float32)\n",
    "std  = torch.sqrt(var.clamp_min(1e-12))\n",
    "\n",
    "print(\"mean:\", mean.tolist())\n",
    "print(\"std :\", std.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6bc8740b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 1000\n",
      "sample tensor: torch.Size([3, 224, 224]) from: /workspaces/eng-ai-agents/assignments/assignment-1/data/frames/frame_00000.png\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class FrameDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        exts = {\".png\",\".jpg\",\".jpeg\",\".bmp\",\".webp\"}\n",
    "        self.paths = []\n",
    "        for dp, _, fns in os.walk(root):\n",
    "            for fn in fns:\n",
    "                if os.path.splitext(fn.lower())[1] in exts:\n",
    "                    self.paths.append(os.path.join(dp, fn))\n",
    "        self.paths.sort()\n",
    "\n",
    "    def __len__(self): return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        img = io.read_image(path)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, path\n",
    "\n",
    "transform = v2.Compose([\n",
    "    v2.Resize((224, 224)),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=mean, std=std),\n",
    "])\n",
    "\n",
    "dataset = FrameDataset(FRAMES_DIR, transform=transform)\n",
    "print(\"dataset size:\", len(dataset))\n",
    "x0, p0 = dataset[0]\n",
    "print(\"sample tensor:\", x0.shape, \"from:\", p0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04b4f21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/eng-ai-agents/assignments/assignment-1/data/preview/grid.png'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def denorm(x, m, s):\n",
    "    return (x * s[:, None, None] + m[:, None, None]).clamp(0,1)\n",
    "\n",
    "n = min(16, len(dataset))\n",
    "imgs = []\n",
    "for i in range(n):\n",
    "    x, _ = dataset[i]\n",
    "    imgs.append(denorm(x, mean, std))\n",
    "\n",
    "grid = make_grid(torch.stack(imgs), nrow=4)\n",
    "grid_path = os.path.join(PREVIEW_DIR, \"grid.png\")\n",
    "save_image(grid, grid_path)\n",
    "grid_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b37a75be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "astronaut raw: torch.Size([3, 512, 512]) torch.uint8\n",
      "astronaut transformed: torch.Size([3, 224, 224]) torch.float32 min/max: -1.8853892087936401 3.811460018157959\n"
     ]
    }
   ],
   "source": [
    "img_u8 = io.read_image(ASTRONAUT_PATH)\n",
    "img_tf = transform(img_u8)\n",
    "print(\"astronaut raw:\", img_u8.shape, img_u8.dtype)\n",
    "print(\"astronaut transformed:\", img_tf.shape, img_tf.dtype,\n",
    "      \"min/max:\", float(img_tf.min()), float(img_tf.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c891de3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |███████████████| 1000/1000 [189.1ms elapsed, 0s remaining, 5.3K samples/s]     \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://0.0.0.0:5151/?notebook=True&subscription=f1a9f91a-37f7-4e28-a8b0-9c431eae02ae\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f235f06ce10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset:          assignment1_frames\n",
       "Media type:       image\n",
       "Num samples:      1000\n",
       "Selected samples: 0\n",
       "Selected labels:  0\n",
       "Session URL:      http://0.0.0.0:5151/"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "from fiftyone import types\n",
    "\n",
    "fo.config.notebook = True\n",
    "fo.config.database_validation = False\n",
    "\n",
    "try:\n",
    "    fo.close_app()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "name = \"assignment1_frames\"\n",
    "if name in fo.list_datasets():\n",
    "    fo.delete_dataset(name)\n",
    "\n",
    "ds = fo.Dataset.from_dir(\n",
    "    dataset_dir=str(FRAMES_DIR),\n",
    "    dataset_type=types.ImageDirectory,\n",
    "    name=name,\n",
    ")\n",
    "\n",
    "session = fo.launch_app(ds)\n",
    "session"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90e616d7",
   "metadata": {},
   "source": [
    "# Assignment 1 Coding\n",
    "\n",
    "Custom Torchvision dataset: 25 points\n",
    "Transformations: 25 points\n",
    "Visualization: 25 points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "febdd7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WS         : /workspaces/eng-ai-agents\n",
      "DATA_DIR   : /workspaces/eng-ai-agents/data\n",
      "VIDEO_PATH : /workspaces/eng-ai-agents/data/video.mp4 exists: False\n",
      "ASTRONAUT  : /workspaces/eng-ai-agents/data/astronaut.jpg exists: False\n",
      "torch: 2.8.0+cpu\n",
      "torchvision: 0.23.0+cpu\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os, torch, torchvision\n",
    "import torchvision.io as io\n",
    "import torchvision.transforms.v2 as v2\n",
    "from torchvision.utils import make_grid, save_image\n",
    "\n",
    "WS = Path(os.environ.get(\"WORKSPACE_DIR\", \"/workspaces/eng-ai-agents/assignments/assignment-1\"))\n",
    "\n",
    "DATA_DIR    = (WS / \"data\").resolve()\n",
    "FRAMES_DIR  = (DATA_DIR / \"frames\").resolve()\n",
    "PREVIEW_DIR = (DATA_DIR / \"preview\").resolve()\n",
    "\n",
    "VIDEO_PATH = DATA_DIR / \"video.mp4\"\n",
    "ASTRONAUT_PATH = DATA_DIR / \"astronaut.jpg\"\n",
    "\n",
    "for d in (DATA_DIR, FRAMES_DIR, PREVIEW_DIR):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"WS         :\", WS)\n",
    "print(\"DATA_DIR   :\", DATA_DIR)\n",
    "print(\"VIDEO_PATH :\", VIDEO_PATH, \"exists:\", VIDEO_PATH.exists())\n",
    "print(\"ASTRONAUT  :\", ASTRONAUT_PATH, \"exists:\", ASTRONAUT_PATH.exists())\n",
    "\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"torchvision:\", torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78d9999d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "PyAV is not installed, and is necessary for the video operations in torchvision.\nSee https://github.com/mikeboers/PyAV#installation for instructions on how to\ninstall PyAV on your system.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m vframes, _, info = \u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mVIDEO_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpts_unit\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msec\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m T = \u001b[38;5;28mint\u001b[39m(vframes.shape[\u001b[32m0\u001b[39m])\n\u001b[32m      4\u001b[39m target = \u001b[38;5;28mmin\u001b[39m(\u001b[32m1000\u001b[39m, T)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/torchvision/io/video.py:321\u001b[39m, in \u001b[36mread_video\u001b[39m\u001b[34m(filename, start_pts, end_pts, pts_unit, output_format)\u001b[39m\n\u001b[32m    319\u001b[39m     vframes, aframes, info = _video_opt._read_video(filename, start_pts, end_pts, pts_unit)\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m     \u001b[43m_check_av_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m end_pts \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    324\u001b[39m         end_pts = \u001b[38;5;28mfloat\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33minf\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/torchvision/io/video.py:46\u001b[39m, in \u001b[36m_check_av_available\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_check_av_available\u001b[39m() -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(av, \u001b[38;5;167;01mException\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m av\n",
      "\u001b[31mImportError\u001b[39m: PyAV is not installed, and is necessary for the video operations in torchvision.\nSee https://github.com/mikeboers/PyAV#installation for instructions on how to\ninstall PyAV on your system.\n"
     ]
    }
   ],
   "source": [
    "vframes, _, info = io.read_video(VIDEO_PATH, pts_unit=\"sec\")\n",
    "T = int(vframes.shape[0])\n",
    "\n",
    "target = min(1000, T)\n",
    "idxs = torch.linspace(0, T - 1, steps=target).round().to(torch.int64)\n",
    "\n",
    "for i, t in enumerate(idxs.tolist()):\n",
    "    frame = vframes[t].permute(2, 0, 1)        # to C,H,W\n",
    "    save_image(frame.float() / 255.0, os.path.join(FRAMES_DIR, f\"frame_{i:05d}.png\"))\n",
    "\n",
    "print(f\"Saved {target} frames â†’ {FRAMES_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd4675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted([os.path.join(FRAMES_DIR, f) for f in os.listdir(FRAMES_DIR)\n",
    "                if f.lower().endswith((\".png\",\".jpg\",\".jpeg\",\".bmp\",\".webp\"))])\n",
    "\n",
    "sum_c   = torch.zeros(3, dtype=torch.float64)\n",
    "sumsq_c = torch.zeros(3, dtype=torch.float64)\n",
    "total_px = 0\n",
    "\n",
    "for p in files:\n",
    "    x = io.read_image(p).to(torch.float32) / 255.0  # C,H,W in [0,1]\n",
    "    c, h, w = x.shape\n",
    "    flat = x.reshape(c, -1)\n",
    "    sum_c   += flat.sum(dim=1, dtype=torch.float64)\n",
    "    sumsq_c += (flat**2).sum(dim=1, dtype=torch.float64)\n",
    "    total_px += h * w\n",
    "\n",
    "mean = (sum_c / total_px).to(torch.float32)\n",
    "var  = (sumsq_c / total_px - (mean.to(torch.float64)**2)).to(torch.float32)\n",
    "std  = torch.sqrt(var.clamp_min(1e-12))\n",
    "\n",
    "print(\"mean:\", mean.tolist())\n",
    "print(\"std :\", std.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc8740b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class FrameDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        exts = {\".png\",\".jpg\",\".jpeg\",\".bmp\",\".webp\"}\n",
    "        self.paths = []\n",
    "        for dp, _, fns in os.walk(root):\n",
    "            for fn in fns:\n",
    "                if os.path.splitext(fn.lower())[1] in exts:\n",
    "                    self.paths.append(os.path.join(dp, fn))\n",
    "        self.paths.sort()\n",
    "\n",
    "    def __len__(self): return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        img = io.read_image(path)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, path\n",
    "\n",
    "transform = v2.Compose([\n",
    "    v2.Resize((224, 224)),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=mean, std=std),\n",
    "])\n",
    "\n",
    "dataset = FrameDataset(FRAMES_DIR, transform=transform)\n",
    "print(\"dataset size:\", len(dataset))\n",
    "x0, p0 = dataset[0]\n",
    "print(\"sample tensor:\", x0.shape, \"from:\", p0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b4f21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm(x, m, s):\n",
    "    return (x * s[:, None, None] + m[:, None, None]).clamp(0,1)\n",
    "\n",
    "n = min(16, len(dataset))\n",
    "imgs = []\n",
    "for i in range(n):\n",
    "    x, _ = dataset[i]\n",
    "    imgs.append(denorm(x, mean, std))\n",
    "\n",
    "grid = make_grid(torch.stack(imgs), nrow=4)\n",
    "grid_path = os.path.join(PREVIEW_DIR, \"grid.png\")\n",
    "save_image(grid, grid_path)\n",
    "grid_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37a75be",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_u8 = io.read_image(ASTRONAUT_PATH)                  # uint8 CxHxW\n",
    "img_tf = transform(img_u8)                              # normalized 224x224 float32\n",
    "print(\"astronaut raw:\", img_u8.shape, img_u8.dtype)\n",
    "print(\"astronaut transformed:\", img_tf.shape, img_tf.dtype,\n",
    "      \"min/max:\", float(img_tf.min()), float(img_tf.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c891de3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "from fiftyone import types\n",
    "\n",
    "name = \"assignment1_frames\"\n",
    "if name in fo.list_datasets():\n",
    "    fo.delete_dataset(name)\n",
    "\n",
    "fod = fo.Dataset.from_dir(\n",
    "    dataset_dir=FRAMES_DIR,\n",
    "    dataset_type=types.ImageDirectory,\n",
    "    name=name,\n",
    ")\n",
    "\n",
    "session = fo.launch_app(fod)\n",
    "session"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

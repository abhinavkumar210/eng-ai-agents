{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d55a8e0",
   "metadata": {},
   "source": [
    "# Assignment 3 â€” Part 4: Video Inference + Tracking\n",
    "\n",
    "Abhinav Kumar\n",
    "11/2/2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7915ecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np, torch, torch.nn as nn, torch.nn.functional as F, timm\n",
    "from torchvision import transforms as T\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "IMG_SIZE = 224; THR = 0.5\n",
    "\n",
    "class ConvBNReLU(nn.Sequential):\n",
    "    def __init__(self, in_c, out_c, k=3, s=1, p=1):\n",
    "        super().__init__(nn.Conv2d(in_c, out_c, k, s, p, bias=False),\n",
    "                         nn.BatchNorm2d(out_c), nn.ReLU(inplace=True))\n",
    "def make_backbone(name=\"vit_base_patch16_224.dino\"):\n",
    "    try:\n",
    "        m = timm.create_model(name, features_only=True, pretrained=True); ch = m.feature_info.channels()\n",
    "    except Exception:\n",
    "        m = timm.create_model(\"resnet50\", features_only=True, pretrained=True); ch = m.feature_info.channels()\n",
    "    return m, ch\n",
    "class FPNDecoder(nn.Module):\n",
    "    def __init__(self, feat_channels, out_ch=128):\n",
    "        super().__init__()\n",
    "        self.lat = nn.ModuleList([nn.Conv2d(c, out_ch, 1) for c in feat_channels])\n",
    "        self.smooth = nn.ModuleList([ConvBNReLU(out_ch, out_ch) for _ in feat_channels])\n",
    "    def forward(self, feats):\n",
    "        feats = feats[-4:] if len(feats)>=4 else feats\n",
    "        x=None; outs=[]\n",
    "        for i in reversed(range(len(feats))):\n",
    "            f = self.lat[i](feats[i])\n",
    "            if x is None: x=f\n",
    "            else: x = f + F.interpolate(x, size=f.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "            x = self.smooth[i](x); outs.append(x)\n",
    "        outs = list(reversed(outs))\n",
    "        size = outs[0].shape[-2:]\n",
    "        up = [F.interpolate(o, size, mode='bilinear', align_corners=False) for o in outs]\n",
    "        return torch.cat(up, dim=1)\n",
    "class SegModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone, ch = make_backbone()\n",
    "        for p in self.backbone.parameters(): p.requires_grad=False\n",
    "        self.decoder = FPNDecoder(ch)\n",
    "        self.head = nn.Sequential(ConvBNReLU(128*min(4, len(ch)), 256),\n",
    "                                  ConvBNReLU(256, 128),\n",
    "                                  nn.Conv2d(128, 1, 1))\n",
    "    def forward(self, x):\n",
    "        feats = self.backbone(x)\n",
    "        dec = self.decoder(feats)\n",
    "        logit = self.head(dec)\n",
    "        return F.interpolate(logit, size=x.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "def iou(a,b):\n",
    "    xA=max(a[0],b[0]); yA=max(a[1],b[1]); xB=min(a[2],b[2]); yB=min(a[3],b[3])\n",
    "    inter=max(0,xB-xA)*max(0,yB-yA)\n",
    "    areaA=max(0,a[2]-a[0])*max(0,a[3]-a[1]); areaB=max(0,b[2]-b[0])*max(0,b[3]-b[1])\n",
    "    return inter/(areaA+areaB-inter+1e-6)\n",
    "class Track:\n",
    "    def __init__(self, tid, box): self.id=tid; self.box=box; self.miss=0\n",
    "class SimpleDeepSort:\n",
    "    def __init__(self, iou_thresh=0.3, max_miss=10):\n",
    "        self.iou_thresh=iou_thresh; self.max_miss=max_miss; self.tracks=[]; self.next_id=1\n",
    "    def update(self, dets):\n",
    "        if not self.tracks:\n",
    "            for d in dets: self._start(d)\n",
    "        else:\n",
    "            used=set(); assigned=set()\n",
    "            I=np.zeros((len(self.tracks), len(dets)), dtype=np.float32)\n",
    "            for i,t in enumerate(self.tracks):\n",
    "                for j,d in enumerate(dets): I[i,j]=iou(t.box,d)\n",
    "            while True:\n",
    "                i,j=np.unravel_index(np.argmax(I), I.shape)\n",
    "                if I[i,j]<self.iou_thresh: break\n",
    "                if i in used or j in assigned: I[i,j]=-1; continue\n",
    "                self.tracks[i].box=dets[j]; self.tracks[i].miss=0\n",
    "                used.add(i); assigned.add(j); I[i,:]=-1; I[:,j]=-1\n",
    "            for j,d in enumerate(dets):\n",
    "                if j not in assigned: self._start(d)\n",
    "            for k,t in enumerate(self.tracks):\n",
    "                if k not in used: t.miss+=1\n",
    "            self.tracks=[t for t in self.tracks if t.miss<=self.max_miss]\n",
    "        return [(t.id, t.box.copy()) for t in self.tracks]\n",
    "    def _start(self,d): self.tracks.append(Track(self.next_id,d)); self.next_id+=1\n",
    "\n",
    "model = SegModel().to(device).eval()\n",
    "t_img = T.Compose([T.Resize((IMG_SIZE, IMG_SIZE)), T.ToTensor()])\n",
    "\n",
    "def mask_to_boxes(mask):\n",
    "    num, labels = cv2.connectedComponents(mask.astype(np.uint8))\n",
    "    boxes=[]\n",
    "    for k in range(1,num):\n",
    "        ys, xs = np.where(labels==k)\n",
    "        if len(xs)==0 or len(ys)==0: continue\n",
    "        x1,x2,y1,y2 = xs.min(), xs.max(), ys.min(), ys.max()\n",
    "        if (x2-x1)*(y2-y1) > 50:\n",
    "            boxes.append(np.array([x1,y1,x2,y2], dtype=np.float32))\n",
    "    return boxes\n",
    "\n",
    "input_video = \"input.mp4\"\n",
    "output_video = \"tracked_output.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(input_video)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) or 30\n",
    "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)); h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "writer = cv2.VideoWriter(output_video, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w,h))\n",
    "tracker = SimpleDeepSort()\n",
    "\n",
    "while True:\n",
    "    ok, frame = cap.read()\n",
    "    if not ok: break\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    inp = cv2.resize(rgb, (IMG_SIZE, IMG_SIZE))\n",
    "    ten = torch.from_numpy(inp).permute(2,0,1).float()/255.0\n",
    "    with torch.no_grad():\n",
    "        prob = torch.sigmoid(model(ten[None].to(device)))[0,0].cpu().numpy()\n",
    "    mask_small = (prob>THR).astype(np.uint8)\n",
    "    mask = cv2.resize(mask_small, (w,h), interpolation=cv2.INTER_NEAREST)\n",
    "    boxes = mask_to_boxes(mask)\n",
    "    tracks = tracker.update(boxes)\n",
    "\n",
    "    out = frame.copy()\n",
    "    color = np.zeros_like(out); color[...,2]=255\n",
    "    overlay = (out*0.7 + color*0.3*mask[...,None]).astype(np.uint8)\n",
    "    for tid, bb in tracks:\n",
    "        x1,y1,x2,y2 = map(int, bb)\n",
    "        cv2.rectangle(overlay, (x1,y1),(x2,y2),(0,255,0),2)\n",
    "        cv2.putText(overlay, f\"ID {tid}\", (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)\n",
    "    cv2.putText(overlay, f\"Dents: {len(tracks)}\", (12,28), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,0,255), 2)\n",
    "    writer.write(overlay)\n",
    "\n",
    "cap.release(); writer.release()\n",
    "print(\"Saved:\", output_video)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
